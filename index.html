<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Wells Fargo Analytics by leomeloj</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-dark.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script src="javascripts/navigator.js"></script>
    <script src="javascripts/respond.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <!--[if lt IE 8]>
    <link rel="stylesheet" href="stylesheets/ie.css">
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>
      <div id="header">
        <nav>
          <li class="fork"><a href="https://github.com/leomeloj/wells-fargo-analytics">View On GitHub</a></li>
          <li class="downloads"><a href="https://github.com/leomeloj/wells-fargo-analytics/zipball/master">ZIP</a></li>
          <li class="downloads"><a href="https://github.com/leomeloj/wells-fargo-analytics/tarball/master">TAR</a></li>
          <li class="title">DOWNLOADS</li>
        </nav>
      </div><!-- end header -->

    <div class="wrapper">
      <nav class="navigator">
        <ul>
          <li class="tag-h1">
            <a href="#organizing_data"> Organizing the data</a>
          </li>
          <li class="tag-h2">
            <a href="#organizing_data"> Creating the dataset</a>
          </li>
          <li class="tag-h2">
            <a href="#corpus_cleanup"> Corpus Creation and Cleanup</a>
          </li>
          <li class="tag-h1">
            <a href="#analysing-data"> Analysing the Data</a>
          </li>
          <li class="tag-h2">
            <a href="#analysing-data"> Percentage of Positives and Negatives</a>
          </li>
          <li class="tag-h2">
            <a href="#word-clouds"> Word Clouds</a>
          </li>
        </ul>
      </nav>

      <section>
        <div id="title">
          <h1>Wells Fargo Analytics</h1>
          <p></p>
          <hr>
          <span class="credits left">Project maintained by <a href="https://github.com/leomeloj">leomeloj</a></span>
          <span class="credits right">Hosted on GitHub Pages &mdash; Theme by <a href="https://twitter.com/michigangraham">mattgraham</a></span>
        </div>

        <h3>
<a id="organizing_data" class="anchor" href="#organizing_data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Organizing the data:</h3>

<p>The team started by identifying in each post what bank was being talked about. By a simple string search, we found out the indexes of the posts that represents each bank. For example: the posts 1, 3, 4 and 5 talks about bank A while posts 2, 6 and 8 about bank B. So we created a column that represents the bank talked in the post:</p>
  <code><p>
         bankA.idx = which(sapply(df.texts.clean$FullText,function(x) grepl("BankA",x)))
         bankB.idx = which(sapply(df.texts.clean$FullText,function(x) grepl("BankB",x)))
         bankC.idx = which(sapply(df.texts.clean$FullText,function(x) grepl("BankC",x)))
         bankD.idx = which(sapply(df.texts.clean$FullText,function(x) grepl("BankD",x))) 
  </p></code>
  Making the dataframe looks like that:
  <img style="display: block; margin: 10px auto" src="https://raw.githubusercontent.com/leomeloj/wells-fargo-analytics/master/dataWithBanks.png" alt="dataframeWithBanks"/>
  <p>Afterwards, we divided the dataframe in two: Positive posts and Negative posts. In order to do that, we used a positive and a negative corpus and we score each post by how positive and how negative it was.</p>
  <p>Basicaly, for each positive word found on a post his score was incremented by 1 and for each negative it was decremented by 1. Then, for those posts with a score lower than -2 or higher than +2 we would consider it negative or positive respectively. The code is the above:</p>
  <code><p style="margin-left: 20px">score.sentiment = function(sentences, pos.words, neg.words, .progress='none') { <br/>
  require(plyr)<br/>
  require(stringr)<br/>
  <br/>
  <span># we got a vector of sentences. plyr will handle a list </span><br/>
  <span> # or a vector as an "l" for us</span><br/>
  <span># we want a simple array ("a") of scores back, so we use</span> <br/>
  <span># "l" + "a" + "ply" = "laply":</span><br/>
  scores = laply(sentences, function(sentence, pos.words, neg.words) {<br/>
    <br/>
    <span># clean up sentences with R's regex-driven global substitute, gsub():</span><br/>
    sentence = gsub('[[:punct:]]', '', sentence)<br/>
    sentence = gsub('[[:cntrl:]]', '', sentence)<br/>
    sentence = gsub('\\d+', '', sentence)<br/>
    <span># and convert to lower case:</span><br/>
    sentence = tolower(sentence)<br/>
    <br/>
    <span># split into words. str_split is in the stringr package</span><br/>
    word.list = str_split(sentence, '\\s+')<br/>
    <span># sometimes a list() is one level of hierarchy too much</span><br/>
    words = unlist(word.list)<br/>
    <br/>
    <span># compare our words to the dictionaries of positive & negative terms</span><br/>
    pos.matches = match(words, pos.words)<br/>
    neg.matches = match(words, neg.words)<br/>
    <br/>
    <span># match() returns the position of the matched term or NA</span><br/>
    <span># we just want a TRUE/FALSE:</span><br/>
    pos.matches = !is.na(pos.matches)<br/>
    neg.matches = !is.na(neg.matches)<br/>
    <br/>
    <span># and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():</span><br/>
    score = sum(pos.matches) - sum(neg.matches)<br/>
    <br/>
    return(score)<br/>
  }, pos.words, neg.words, .progress=.progress )<br/>
  <br/>
  scores.df = data.frame(score=scores, text=sentences)<br/>
  return(scores.df)<br/>
}<br/>
<br/>
<br/>
<span>#scores = score.sentiment(df.new$FullText, pos, neg, .progress='text')</span><br/>
<br/>
scores = score.sentiment(df.texts.clean[,1], pos, neg, .progress='text')<br/>
scores$very.pos = as.numeric(scores$score >= 1)<br/>
scores$very.neg = as.numeric(scores$score <= -1)<br/>
scores$Month = df.texts.clean$Month<br/>
scores$BankID = df.texts.clean$BankID<br/>
<br/>
scores$text = lapply(scores$text, as.character)<br/>
<br/>
<span># how many very positives and very negatives</span><br/>
numpos = sum(scores$very.pos)<br/>
numneg = sum(scores$very.neg)<br/>
<br/>
<span># create a df with only negative sentences</span><br/>
<span>#For Generating the dataframes separeted by social media type, use the two lines below </span><br/>
<span>#df.negative.twitter = scores[(scores$very.neg == 1 & scores$mediatype == "twitter"),c(2,5)]</span><br/>
<span>#df.negative.facebook = scores[(scores$very.neg == 1 & scores$mediatype == "facebook"),c(2,5)]</span><br/>
df.negative = scores[scores$very.neg == 1, c(2,5,6)]<br/>
df.positive = scores[scores$very.pos == 1, c(2,5,6)]<br/>
<br/>
<span>#BankA</span><br/>
df.bankA.negative = scores[(scores$BankID == "BankA" & scores$very.neg == 1), c(2, 5)]<br/>
df.bankA.positive = scores[(scores$BankID == "BankA" & scores$very.pos == 1), c(2, 5)]<br/>
<span>#BankB</span><br/>
df.bankB.negative = scores[(scores$BankID == "BankB" & scores$very.neg == 1), c(2, 5)]<br/>
df.bankB.positive = scores[(scores$BankID == "BankB" & scores$very.pos == 1), c(2, 5)]<br/>
<span>#BankC</span><br/>
df.bankC.negative = scores[(scores$BankID == "BankC" & scores$very.neg == 1), c(2, 5)]<br/>
df.bankC.positive = scores[(scores$BankID == "BankC" & scores$very.pos == 1), c(2, 5)]<br/>
<span>#BankD</span><br/>
df.bankD.negative = scores[(scores$BankID == "BankD" & scores$very.neg == 1), c(2, 5)]<br/>
df.bankD.positive = scores[(scores$BankID == "BankD" & scores$very.pos == 1), c(2, 5)]<br/>
<span>#Banke</span><br/>
df.banke.negative = scores[(scores$BankID == "Banke" & scores$very.neg == 1), c(2, 5)]<br/>
df.banke.positive = scores[(scores$BankID == "Banke" & scores$very.pos == 1), c(2, 5)]<br/>
  </p></code>
    <br/>
  <p>With the dataframe divided by that and having the banks in the respective posts, we have the data organized as that:</p>
  <img style="display: block; margin: 10px auto" src="https://github.com/leomeloj/wells-fargo-analytics/blob/master/dataOrganization1.png?raw=true" alt="Organized per banks and score"/>

<hr style="margin-top: 30px;">

<h3>
<a id="corpus_cleanup" class="anchor" href="#corpus_cleanup" aria-hidden="true"><span class="octicon octicon-link"></span></a> Creation of a Corpus to Clean the Text and create Word Clouds</h3>

<p>With the dataset organized we created the corpus to create the word clouds. With the corpus created, it's possible to clean it by removing unwanted words and terms. We did a function that was used to clean up the texts and generate the word cloud:</p>
<code><p style="margin-left: 20px">
  createWordCloud = function(dataset){<br/>
<span>  #Create a corpus using a dataframe</span><br/>
  <span>#corpus <- Corpus(DataframeSource(dataset))</span><br/>
  corpus <- VCorpus(VectorSource(dataset$text))<br/>
  
  <span>#clean the corpus text</span><br/>
  corpus <- tm_map(corpus, content_transformer(tolower))  <br/>
  corpus <- tm_map(corpus, removeWords, c("name", "bank", "twit_hndl", "AD", "twit_hnld_bankb_help","ADRESS", "twit","twithndlbankc",<br/>
                                          "twit_hndl_banka", "twit_hndl_bankb", "twit_hndl_bankd", "twit_hndl_banke",<br/>
                                          "name_resp", "internet", "hndl", "twit_hndl_banka","twit_hndl_bankc", <br/>
                                          "banka", "bankb", "feedbankb", "bankc", "bankd", "banke"))<br/>
  corpus <- tm_map(corpus, stripWhitespace)<br/>
  corpus <- tm_map(corpus, removePunctuation)<br/>
  corpus <- tm_map(corpus, removeNumbers)<br/>
  corpus <- tm_map(corpus, removeWords, stopwords("english"))<br/>
  <br/>
  <span>#Creates a Document Term Matrix to be used in the wordcloud</span><br/>
  corpusText <- tm_map(corpus, PlainTextDocument)<br/>
  dtm <- DocumentTermMatrix(corpusText)<br/>
  <br/>
  tdm <- TermDocumentMatrix(corpus)<br/>
  <span>#Get the frequency of the words</span> <br/>
  freq <- colSums(as.matrix(dtm))   <br/>
  length(freq)   <br/>
  ord <- order(freq)   <br/>
  m <- as.matrix(dtm)   <br/>
  dim(m)   <br/>
  <br/>
  <span>#Sort the words by frequency rank</span><br/>
  freq<- sort(colSums(as.matrix(dtm)), decreasing=TRUE)<br/>
  <span>#Create a txt file with the ranked words</span><br/>
  write.table(freq, file = "input.txt")<br/>
  <br/>
  dtms <- removeSparseTerms(dtm, 0.25) # Prepare the data (max 15% empty space)   <br/>
  freq <- colSums(as.matrix(dtm)) # Find word frequencies   <br/>
  dark2 <- brewer.pal(6, "Dark2")   <br/>
  <span>#Create the wordcloud</span><br/>
  wordcloud(names(freq), freq, max.words=100, rot.per=0.2, colors=dark2)  <br/>
}<br/>
  
</p></code>

<p> Afterwards, we used that function to generate the WordClouds for each dataframe we wanted to analyze: </p>
<code> <p style="margin-left: 20px">
  <span>#Call the function to generate different wordclouds</span> <br/>
<span>#Creating clouds to see the diffence between what banks A, B, C and D have different than the other banks</span> <br/>
createWordCloud(scores[(scores$BankID != "Banke" & scores$very.pos == 1),c(2,3)]) <br/>
createWordCloud(scores[(scores$BankID == "Banke" & scores$very.pos == 1),c(2,3)]) <br/>
 <br/>
createWordCloud(scores[(scores$BankID != "Banke" & scores$very.neg == 1),c(2,3)]) <br/>
createWordCloud(scores[(scores$BankID == "Banke" & scores$very.neg == 1),c(2,3)]) <br/>
 <br/>
<span>#Create clouds to see the difference between the banks A, B, C and D </span><br/>
<span>#createWordCloud(scores[(scores$BankID == "Banke"),c(2,3)])</span> <br/>
createWordCloud(scores[(scores$very.neg == 1),c(2,3)]) <br/>
createWordCloud(scores[(scores$very.pos == 1),c(2,3)]) <br/>
 <br/>
createWordCloud(scores[,c(2,3)]) <br/>
createWordCloud(df.bankA.positive) <br/>
createWordCloud(df.bankA.negative) <br/>
createWordCloud(df.bankB.negative) <br/>
createWordCloud(df.bankB.positive) <br/>
createWordCloud(df.bankC.negative) <br/>
createWordCloud(df.bankC.positive) <br/>
createWordCloud(df.bankD.negative) <br/>
createWordCloud(df.bankD.positive) <br/>
createWordCloud(df.banke.negative) <br/>
createWordCloud(df.banke.positive) <br/>
</p></code>
<h3>
<a id="analysing-data" class="anchor" href="#analysing-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Analysing the Data</h3>
<h4>Percentage of Positives and Negatives</h4>
<p>The first analysis we made was how many positives and negative posts each bank had. The code can be checked below:</p>
<code> <p style="margin-left: 20px">
  <span>#BANKA NUMBERS</span><br/>
bankA.positive.counter = sum(scores[scores$BankID == "BankA", 3])<br/>
bankA.negative.counter = sum(scores[scores$BankID == "BankA", 4])<br/>
bankA.positive.percentage = (bankA.positive.counter*100) / (bankA.positive.counter + bankA.negative.counter)<br/>
bankA.negative.percentage = (bankA.negative.counter*100) / (bankA.positive.counter + bankA.negative.counter)<br/>
<br/>
<span>#BANKB NUMBERS</span><br/>
bankB.positive.counter = sum(scores[scores$BankID == "BankB", 3])<br/>
bankB.negative.counter = sum(scores[scores$BankID == "BankB", 4])<br/>
bankB.positive.percentage = (bankB.positive.counter*100) / (bankB.positive.counter + bankB.negative.counter)<br/>
bankB.negative.percentage = (bankB.negative.counter*100) / (bankB.positive.counter + bankB.negative.counter)<br/>
<br/>
<span>#BANKC NUMBERS</span><br/>
bankC.positive.counter = sum(scores[scores$BankID == "BankC", 3])<br/>
bankC.negative.counter = sum(scores[scores$BankID == "BankC", 4])<br/>
bankC.positive.percentage = (bankC.positive.counter*100) / (bankC.positive.counter + bankC.negative.counter)<br/>
bankC.negative.percentage = (bankC.negative.counter*100) / (bankC.positive.counter + bankC.negative.counter)<br/>
<br/>
<span>#BANKD NUMBERS</span><br/>
bankD.positive.counter = sum(scores[scores$BankID == "BankD", 3])<br/>
bankD.negative.counter = sum(scores[scores$BankID == "BankD", 4])<br/>
bankD.positive.percentage = (bankD.positive.counter*100) / (bankD.positive.counter + bankD.negative.counter)<br/>
bankD.negative.percentage = (bankD.negative.counter*100) / (bankD.positive.counter + bankD.negative.counter)<br/>
<br/>
<span>#BANKe NUMBERS</span><br/>
banke.positive.counter = sum(scores[scores$BankID == "Banke", 3])<br/>
banke.negative.counter = sum(scores[scores$BankID == "Banke", 4])<br/>
banke.positive.percentage = (banke.positive.counter*100) / (banke.positive.counter + banke.negative.counter)<br/>
banke.negative.percentage = (banke.negative.counter*100) / (banke.positive.counter + banke.negative.counter)<br/>
<br/>
<br/>
<span>#Total Positives</span><br/>
total.positives = sum(scores$very.pos)<br/>
<br/>

dat.positive<-data.frame(<br/>
  banks = factor(c("BankA","BankB","BankC","BankD", "Banke"), levels=c("BankA","BankB", "BankC", "BankD", "Banke")),<br/>
  positive = c((bankA.positive.counter*100)/total.positives, (bankB.positive.counter*100)/total.positives, <br/>
               (bankC.positive.counter*100)/total.positives, (bankD.positive.counter*100)/total.positives, (banke.positive.counter*100)/total.positives) <br/>
)<br/>
(p <- qplot(banks, positive, data=dat.positive, position="dodge", geom="bar", stat="identity"))<br/>
<br/>
<span>#TotalNegatives</span><br/>
total.negative = sum(scores$very.neg)<br/>
<br/>

dat.negative<-data.frame(<br/>
  banks = factor(c("BankA","BankB","BankC","BankD", "Banke"), levels=c("BankA","BankB", "BankC", "BankD", "Banke")),<br/>
  positive = c((bankA.negative.counter*100)/total.positives, (bankB.negative.counter*100)/total.negative, <br/>
               (bankC.negative.counter*100)/total.positives, (bankD.negative.counter*100)/total.negative, (banke.negative.counter*100)/total.positives)<br/>
)<br/>
<br/>
(p <- qplot(banks, positive, data=dat.negative, position="dodge", geom="bar", stat="identity"))<br/>
</p></code>
<p> By analysing the graphics we can check that Bank B is the best ranked, having both the higher positive and lower negative posts percentage while BankC have the lowest positive and higher negative. </p>
<img src="https://github.com/leomeloj/wells-fargo-analytics/blob/master/bankGraphic.png?raw=true" alt="Percentage Graphic" style="margin: 10px auto; display: block">
<br/>
<hr style="margin-top: 30px;">
<h3>
  <a id="word-clouds" class="anchor" href="#word-clouds" aria-hidden="true"><span class="octicon octicon-link"></span></a>Word Clouds</h3>
<p>Using the code described in the last section, we identified the most frequent words in the negative posts and did some analysis on top of them. </p>
<h4>BankA</h4>
<p>The Word Cloud Generated for Bank A is represented below: </p>
<img src="https://github.com/leomeloj/wells-fargo-analytics/blob/master/bankA-negative.png?raw=true" width="554px" alt="BankA Negative WordCloud" style="margin: 10px auto; display: block">
<br/>
<p>For BankA the most frequent words in the negative posts are “ACCOUNT” and “CARD”, followed by words like “PHONE”,
“HELP”, “CUSTOMER”, “SERVICE” and “PROBLEM”, what can lead us to think that customers are really unsatisfied with the
problems solving BankA is providing them, especially the help provided via cell phone.</p>
<br/>
<h4>BankB</h4>
<p>The Word Cloud Generated for Bank B is represented below: </p>
<br/>
<img src="https://github.com/leomeloj/wells-fargo-analytics/blob/master/bankB-negative.png?raw=true" width="554px" alt="BankB Negative WordCloud" style="margin: 10px auto; display: block">
<p>For BankB the most frequent words in the negative posts are “ACCOUNT”, “MONEY” and “FRAUD”, with “PANIC” being a
frequent word as well, what can possibly mean that some customers are afraid of frauds, what makes them really
unsatisfied.</p>
<br/>
<h4>BankC</h4>
<p>The Word Cloud Generated for Bank C is represented below: </p>
<br/>
<img src="https://github.com/leomeloj/wells-fargo-analytics/blob/master/bankC-negative.png?raw=true" width="554px" alt="BankC Negative WordCloud" style="margin: 10px auto; display: block">
<p>For BankC some frequent words in the negative posts are “fund”, “guilty” and “recession” what can lead us to think
that customers are really unsatisfied with BankC’s recessions which are probably decreasing the quality of the bank’s
service. Customers may also be thinking that their funds are in danger in the hands of BankC</p><br/>
<h4>BankD</h4>
<p>The Word Cloud Generated for Bank D is represented below: </p>
<img src="https://github.com/leomeloj/wells-fargo-analytics/blob/master/bankD-negative.png?raw=true" width="554px" alt="BankD Negative WordCloud" style="margin: 10px auto; display: block">
<br/>
<p>For BankD the most frequent words in the negative posts are
“account”, “card” and “CEO”, what actually doesn’t mean too much but can definitely lead us to think that BankD’s
CEO is not satisfying their customers.</p>
<p>Altough when we analyzed the word “CEO” deeper with the software AntConc we realized that BankD’s CEO made a lot
of important declarations about bad moments of the bank (like when BankD was about to enter in an economic crisis)
and that’s why this word appears a lot. It can actually be considered a good thing since the customers may feel more
satisfied having the bank’s CEO talking about the current situation of the company they are trusting their money to.</p>
<hr style="margin-top: 30px;">
<h3>
<a id="positive-corpus" class="anchor" href="#positive-corpus" aria-hidden="true"><span class="octicon octicon-link"></span></a>Analysis of Positive Corpus</h3>
<p>As a complement to my groups work, I analysed the positive corpus, hoping to identify the key words and the positive aspects of each bank.<br/>
As a first step, I ran the code below to generate the WordClouds:</p>
<code><p>
  createWordCloud(df.bankA.positive)
  createWordCloud(df.bankB.positive)
  createWordCloud(df.bankC.positive)
  createWordCloud(df.bankD.positive)
</p></code>
<br/>
<img src="https://github.com/leomeloj/wells-fargo-analytics/blob/master/positive-word-clouds.png?raw=true" alt="Positive Word Cloud" style="display: block; margin: 10px auto">
<p> When I started analysing the positive keywords for bankA, for my surprize, the results were incompatible to the results 
    we found for the negative posts, meaning that the same subject described as a flaw in bankA was result object in the positive aspect.</p>
<p> For example, some of most frequent words in the positive wordcloud are: "ACCOUNT", "SUPPORT", "PHONE" and "CARD". Since those words were present in the negative corpus as well, I decided to use Antconc as a concordancer to help me analyse it.</p>
<h3>
<a id="antconc" class="anchor" href="#antconc" aria-hidden="true"><span class="octicon octicon-link"></span></a>Antconc Analysis</h3>
  <p>Antconc is a freeware corpus analysis toolkit for concordancing and text analysis. It works well, but it have lots of 
     limitations: the text need to be in a .txt format for it to work; the corpus need to be clean; and for the wordlist
     tool (based on frequency) doesn't filter irrelevant words like stopWords.</p>
     <p>Although, if you already know what word you want to analyse, the Concordance tool is really usefull.  You just need to use a
        .txt file as an input and search the word in the concordance tab and you can see all the occurencies of the word in their given context</p>
      <code><p style="margin-left: 20px">
               write.table(df.bankA.positive[,1], file = "positiveCorpusB.txt")<br/>
               write.table(df.bankB.positive[,1], file = "positiveCorpusB.txt")<br/>
               write.table(df.bankC.positive[,1], file = "positiveCorpusB.txt")<br/>
               write.table(df.bankD.positive[,1], file = "positiveCorpusB.txt")<br/>
      </p></code>
      <p>The .txt file is easilly adquire, on every function call above, the algorithm generates an file called input.txt that's exactly
         what the software needs. By running the concordancer with BankA's positive corpus, the result is represented in the printscreen below: 
      </p>
<img src="https://github.com/leomeloj/wells-fargo-analytics/blob/master/bankA-concord.png?raw=true" alt="bankA in Concordancer" style="display: block; margin: 10px auto">
<p>By anaylising the data in AntConc I realized that, in bankA, the majority of the positive posts were not positives towards bankA
  reputation, it was just written on a polite way. For instance, the highlighted post is: "if anyone has a BankA account i would 
  strongly recommend you checking your bank account to make sure that you do not have any unauthorized transactions
  going to paypal. i had money with drawn from my account via paypal to someone i dont evem know". Clearly, that's not a positive
  post for bankA, but it was classified as such.</p>
  <p>Another goal was to identify why bankB have the biggest number of positive posts. For that analysis, I followed the same methodology
      as before. I generated the wordcloud, found the keywords in the positive posts and used AntConc to see the context the words were
      being used:</p>
  <img src="https://github.com/leomeloj/wells-fargo-analytics/blob/master/bankB-concord.png?raw=true" alt="bankB in Concordancer" style="display: block; margin: 10px auto">
  <p>In the image above, the post highlighted says: "[Name] feed BankB is appreciated. [Name], if you have additional concerns please feel free to reach out to us".
     Clearly, this post, like almost every other containing the word "APPRECIATE" in this corpus, is a bankB reply for a user.</p>
    <p> Since the message is filled with polite words, all those posts were classified as positive posts. In that scenario, the percentage
         of community based positive posts are probably diferent than the one reported in our statistics</p>
<h3>
<a id="employee-posts-removed" class="anchor" href="#employee-posts-removed" aria-hidden="true"><span class="octicon octicon-link"></span></a>New Statistics without Employee Posts</h3>
    <p>In that context, I looked for a pattern to identify the posts that were from an employee of the bank and I found out that everyone of them had Name_Resp at the end.
       With that information, I ran a string search algorithm and found out new numbers and statistics, removing the posts published by
       bank employees: </p>
       <code><p>
<span>Calculate the percentages removing the posts from bank employees </span><br/>
bankA.staff.indx = which(sapply(df.bankA.positive$text,function(x) grepl("Name_Resp",x)))<br/>
bankB.staff.indx = which(sapply(df.bankB.positive$text,function(x) grepl("Name_Resp",x)))<br/>
bankC.staff.indx = which(sapply(df.bankC.positive$text,function(x) grepl("Name_Resp",x)))<br/>
bankD.staff.indx = which(sapply(df.bankD.positive$text,function(x) grepl("Name_Resp",x)))<br/>
banke.staff.indx = which(sapply(df.banke.positive$text,function(x) grepl("Name_Resp",x)))<br/>
<br/>
<span>#BANKA NUMBERS</span><br/>
bankA.positive.counter = bankA.positive.counter - length(bankA.staff.indx)<br/>
bankA.positive.percentage = (bankA.positive.counter*100) / (bankA.positive.counter + bankA.negative.counter)<br/>
bankA.negative.percentage = 100 - bankA.positive.percentage<br/>
<br/>
<span>#BANKB NUMBERS</span><br/>
bankB.positive.counter = bankB.positive.counter - length(bankB.staff.indx)<br/>
bankB.positive.percentage = (bankB.positive.counter*100) / (bankB.positive.counter + bankB.negative.counter)<br/>
bankB.negative.percentage = 100 - bankB.positive.percentage<br/>
<br/>
<span>#BANKC NUMBERS</span><br/>
bankC.positive.counter = bankC.positive.counter - length(bankC.staff.indx)<br/>
bankC.positive.percentage = (bankC.positive.counter*100) / (bankC.positive.counter + bankC.negative.counter)<br/>
bankC.negative.percentage = 100 - bankC.positive.percentage<br/>
<br/>
<span>#BANKD NUMBERS</span><br/>
bankD.positive.counter = bankD.positive.counter - length(bankD.staff.indx)<br/>
bankD.positive.percentage = (bankD.positive.counter*100) / (bankD.positive.counter + bankD.negative.counter)<br/>
bankD.negative.percentage = 100 - bankD.positive.percentage<br/>
<br/>
<span>#Banke NUMBERS</span><br/>
banke.positive.counter = banke.positive.counter - length(banke.staff.indx)<br/><br/>
banke.positive.percentage = (banke.positive.counter*100) / (banke.positive.counter + banke.negative.counter)<br/>
banke.negative.percentage = 100 - banke.positive.percentage<br/>
<br/>
       </p></code>
<p>With those number, I created a new graphic that represents better the costumer view of the banks:</p>
<code><p>
<span>#Creates the dataframe with the positive posts</span><br/>
dat.positive<-data.frame(<br/>
  banks = factor(c("BankA","BankB","BankC","BankD", "Banke"), levels=c("BankA","BankB", "BankC", "BankD", "Banke")),<br/>
  positive = c(bankA.positive.percentage, bankB.positive.percentage,<br/> 
                bankC.positive.percentage, bankD.positive.percentage, banke.positive.percentage)<br/>
)<br/>
<span>#Plot the graphic</span><br/>
(p <- qplot(banks, positive, data=dat.positive, position="dodge", geom="bar", <br/>
            stat="identity"))<br/>
</p></code>
<img src="https://github.com/leomeloj/wells-fargo-analytics/blob/master/new-bank-graphic.png?raw=true" alt="New Statistics Graphic" style="display: block; margin: 10px auto">
<p> In that new statistic, bankC still have the worst position in the positive posts. Although, the best rated now is bankD instead of bankB
   who now have a rate worst than bankA as well.</p>
<h3>
<a id="authors-and-contributors" class="anchor" href="#authors-and-contributors" aria-hidden="true"><span class="octicon octicon-link"></span></a>Authors and Contributors</h3>

<p>That was a team project and the team consisted of three computer science majors: Juliana Jalloule <a href="https://github.com/Jalloule" class="user-mention">@jalloule</a>, Julie Pessoa <a href="https://github.com/JuliePessoa" class="user-mention">@juliePessoa</a> and me, Leonardo de Melo <a href="https://github.com/leomeloj" class="user-mention">@leomeloj</a></p>
</section>

    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
  </body>
</html>
